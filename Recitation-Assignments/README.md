

# Teaching Assistants

* [Yavar Taheri Yeganeh](https://github.com/YavarYeganeh) (Email: y.taheriyeganeh@mail.sbu.ac.ir)
  - Office Hours: Sundays and Wednesdays, 12 am to 1 pm, Professor's Office (TBC)
* [Erfaan Rostami Amraei](https://github.com/Erfaan-Rostami) (Email: r.a.erfan@gmail.com)
  
* [Mostafa Khodayari](https://github.com/MSTF4) (Email: mo.khodayari@mail.sbu.ac.ir)
 
* [Esmail Mafakheri](https://github.com/E008001) (Email: e.mafakheri@mail.sbu.ac.ir)
  
**Please Note**: 

* A carbon copy (Cc) of your email communications with TAs must be sent to the following email address (hhhaji@gmail.com).

* Response to emails may take a few days. Please be patient!

# Recitation

* **First Video Tutorial** by [Yavar Taheri Yeganeh](https://github.com/YavarYeganeh) posted on Monday, Esfand 5
   - Brief on Working in Cloud-based Services, such as Google Colab
   - Brief Introduction of GIT
   - Video: Posted in the Skype Group

* **Session One** by [Erfaan Rostami Amraei](https://github.com/Erfaan-Rostami) was on Wednesday, Esfand 7 
   - Introduction to Python

* **Session Two** by [Yavar Taheri Yeganeh](https://github.com/YavarYeganeh) was on Wednesday, Esfand 7 
   - Python Libraries Tutorial
   - Brief Introduction to Python Classes/Objects (Added to the Notebook!)
   - Notebook: [Colab](https://colab.research.google.com/drive/1pIxeznCzX16uI_ONooD644G2kwTrAFUJ)
   
* **Session Three** by [Yavar Taheri Yeganeh](https://github.com/YavarYeganeh) was on Tuesday, Esfand 13
   - The Machine Learning Landscape of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow ](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) 
   - Machine Learning with Scikit-Learn Part 1
   - Notebook: [Colab](https://colab.research.google.com/drive/1e_5IjXWMeJ0pq2UXneKCaT6GVfczJAoN)

*  **Session Four** by [Yavar Taheri Yeganeh](https://github.com/YavarYeganeh) was on Tuesday, Esfand 20
   - Reviewing Session Three
   - End to End Machine Learning Project of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow ](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) 
   - Machine Learning with Scikit-Learn Part 2
   - Notebook: [Colab](https://colab.research.google.com/drive/15pmReFGAfmULTQb6RyZur9n0NCX6n8Tl)
   
* **Session Five** by [Yavar Taheri Yeganeh](https://github.com/YavarYeganeh) was on Tuesday, Esfand 25
   - End to End Machine Learning Project of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow ](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) 
   - Machine Learning with Scikit-Learn Part 3
   - Notebook: [Colab](https://colab.research.google.com/drive/1gbXt3B74FiIiI4jLlqqxTPOm-elHkYY7)
   
* **Session Six** by [Mostafa Khodayari](https://github.com/MSTF4) was on Tuesday, Farvardin 19 
   - Classification of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow ](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) 
   - Machine Learning with Scikit-Learn Part 4
   - Notebook: [Colab](https://colab.research.google.com/drive/1yxOQcpiCIGSmkgB2WwLtkI0x1QEcXKEV)
   
* **Session Seven** by [Mostafa Khodayari](https://github.com/MSTF4) was on Tuesday, Farvardin 26
   - Classification of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow ](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)
   - Machine Learning with Scikit-Learn Part 5
   - Notebook: [Colab](https://colab.research.google.com/drive/1yxOQcpiCIGSmkgB2WwLtkI0x1QEcXKEV)
   
* **Session Eight** by [Erfaan Rostami Amraei](https://github.com/Erfaan-Rostami) was on Tuesday, Ordibehesht 2
   - Training Models of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow ](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) 
   - Machine Learning with Scikit-Learn Part 6
   - Notebook: [Colab](https://colab.research.google.com/drive/1S1RguKRlxG3jE7z1lelIX0Uk3pImr05m#scrollTo=L23wN_05sKC3)
   
* **Session Nine** by [Erfaan Rostami Amraei](https://github.com/Erfaan-Rostami) was on Sunday, Ordibehesht 7

   - Training Models of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow ](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) 
   - Machine Learning with Scikit-Learn Part 7
   - Notebook: [Colab](https://colab.research.google.com/drive/1a0sKKtVQhoyIi0wY8FFqi7G3Jj7pv57B#scrollTo=KQBAFnhMxi3q)
   
* **Session Ten** by [Erfaan Rostami Amraei](https://github.com/Erfaan-Rostami) was on Tuesday, Ordibehesht 16

   - Decision Trees of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow ](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)
   - Machine Learning with Scikit-Learn Part 8
   - Notebook: [Colab](https://colab.research.google.com/drive/1yXm3xz_2GvFDz1KFAOyl20RfQTMOKCfo#scrollTo=S5QOeL61WtP5)

* **Session Eleven** by [Yavar Taheri Yeganeh](https://github.com/YavarYeganeh) was on Tuesday, Ordibehesht 23

   - Ensemble Learning and Random Forests of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow ](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)
   - Machine Learning with Scikit-Learn Part 9
   - Notebook: [Colab](https://colab.research.google.com/drive/1JBohY2HYpWzO987OB8PUo2rOChgome5S?usp=sharing)

* **Session Twelve** by [Erfaan Rostami Amraei](https://github.com/Erfaan-Rostami) was on Tuesday, Ordibehesht 30

   - Dimensionality Reduction of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow ](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)
   - Machine Learning with Scikit-Learn Part 10
   - Notebook: [Colab](https://colab.research.google.com/drive/1vWRGl3V06kbyzsZFsq1TKhXbLI9fzme1#scrollTo=dTORysOwzXS_)
   
* **Session Thirteen** by [Mostafa Khodayari](https://github.com/MSTF4) was on Tuesday, Khordad 6

  - Unsupervised Learning Techniques of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow ](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)
   - Machine Learning with Scikit-Learn Part 11
   - Notebook: [Colab](https://colab.research.google.com/drive/1yNgQVqWZs1iKWCKaNPivuUGJtGAXePuN?usp=sharing)

* **Session Fourteen** by [Yavar Taheri Yeganeh](https://github.com/YavarYeganeh) was on Tuesday, Khordad 13 

   - Intro. to Artificial Neural Networks with Keras of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow ](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)
   - Machine Learning with TensorFlow and Keras Part 1
   - Notebook: [Colab](https://colab.research.google.com/drive/1KmKLAnhT-za1BxUj9EkKZkN5UDzd95A4?usp=sharing)
   
* **Session Fifteen** by [Yavar Taheri Yeganeh](https://github.com/YavarYeganeh) was on Tuesday, Khordad 25 

   - Support Vector Machines of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow ](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)
   - Machine Learning with Scikit-Learn Part 12
   - Notebook: [Colab](https://colab.research.google.com/drive/1jJcdxO0wI8QG3OVwEbiRDCOeo_knS8zY?usp=sharing)

* **Session Sixteen** by [Yavar Taheri Yeganeh](https://github.com/YavarYeganeh) was on Tuesday, Khordad 25 

   - Intro. to Artificial Neural Networks with Keras of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow ](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)
   - Machine Learning with TensorFlow and Keras Part 2
   - Selected Experiments with Artificial Neural Networks
   - Notebook: [Colab](https://colab.research.google.com/drive/1PRvweH1v3LFL85wnlek8RnvQMU7PRHFz?usp=sharing)

# Assignments 

## Assignment Set 1  

* Install Anaconda and Create an Environment.    
* Install Python Packages (Pandas, Scikit-Learn, Matplotlib) and Jupyter Lab in your new Environment.    
* Create a GitHub account.   
* Create a Repository for this Course in your GitHub.  
* Use Markdown to Prepare a Readme file for your Repository. 
* Modify (at least enter your name) and Run the [Sample Notebook](https://github.com/hhaji/Applied-Machine-Learning/blob/master/Recitation-Assignments/assignments-1_sample.ipynb) in your Environment, then Upload it in your Github Repository.

-> Deadline: Saturday, Bahman 26, 23:59 (Advantage ~ 5 Points) - Extended to Sunday Bahman 27, 12:59

## Assignment Set 2

*  Python and Scientific Libraries:

    - Practice Numpy in [LabEx](https://labex.io/courses/100-numpy-exercises) 
    - Practice Pandas in [LabEx](https://labex.io/courses/100-pandas-exercises)   
    - Practice Matplotlib in [LabEx](https://labex.io/courses/draw-2d-and-3d-graphics-by-matplotlib) 
    - Then Push/Upload each of the three Jupyter notebooks using git in the Labex machine. (Try to be creative!)

**Please Note:** In the Labex exercises, each empty cell must be different (modified) from the sample one. Therefore, the completed notebook will have at least 200 outputs. Furthermore, please review the tutorial video for submitting the assignment set 2.

-> Deadline: Saturday, Esfand 10, 23:59 (Advantage ~ 5 Points) - Extended to Saturday, Esfand 17, 23:59

## Assignment Set 3

* Chapter 2 of [Understanding Machine Learning: From Theory to Algorithms](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning)  

    - Exercises: 2.1, 2.2, and 2.3     
    
-> Deadline: Monday, Esfand 19, 23:59 (Announced at Esfand 12) 

## Assignment Set 4

* Machine Learning with Scikit-Learn: Perform a basic Machine Learning Task on the [Coronavirus/Covid-19](https://github.com/CSSEGISandData/COVID-19) Data (infected and death cases in the World and Iran).

    - Visualize total infected and death cases in the World and Iran over time.
    - Perform regressions on the data based on Scikit-learn's Linear Models: Linear and Polynomial (with different degrees) as well as at least one more method.
    - Fit a Gaussian function (curve) to the data.
    - Visualize every model and predict the total infected and death cases in the future.
    - Split data into a train and a test set, then repeat steps 2 to 4 using train data.
    - Evaluate your model predictions by comparing them to the test data.
    - Visualize both approaches (full and train data) for every model.
    - Finally: Employ everything you know about machine learning to develop a model based on the data, capable of offering   optimal prediction on the total infected and death cases in the World and Iran as well as visualization over time. (Try to be creative!)
 
**Please Note:** You can only use [Daily Reports](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports) from January 22 up to March 18. This assignment is closely related to the [Kaggle's COVID19 Global/Local US-CA Forecasting Challenges](https://www.kaggle.com/c/covid19-local-us-ca-forecasting-week-1/overview), therefore, it could also be submitted for the challenge.

-> Deadline: Wednesday, Esfand 28, 23:59 (Announced at Esfand 14) 

## Assignment Set 5

* Chapter 3 of [Understanding Machine Learning: From Theory to Algorithms](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning)  

    - Exercises: 3.2, 3.3, 3.4, 3.5, 3.6, 3.7

-> Deadline: Saturday, Farvardin 9, 23:59 (Announced at Esfand 20)

## Assignment Set 6

* Chapter 6 of  [Understanding Machine Learning: From Theory to Algorithms](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning)

    - Exercises: 6.2, 6.4, 6.6, 6.9, 6.10, and 6.11 

-> Deadline: Saturday, Farvardin 16, 23:59 (Announced at Farvardin 5)

## Assignment Set 7

* Chapter 9 of [Understanding Machine Learning: From Theory to Algorithms](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning)  

    - Exercises: 9.1, 9.3, 9.4, and 9.6   

-> Deadline: Saturday, Farvardin 30, 23:59 (Announced at Farvardin 24)

## Assignment Set 8

* Machine Learning with Scikit-Learn: The [dataset](https://github.com/hhaji/Applied-Machine-Learning/blob/master/Recitation-Assignments/Assignments_Data/Assignment_Set_8_Data.csv) includes the parental level of education, test preparation course, math score, reading and writing score, etc., to understand their impact on overall performance in the 5 groups of students.

    - Classify the specified data using the binary method and then the multi-class method to achieve an accuracy of 90% or more.

-> Deadline: Saturday, Ordibehesht 13, 23:59 (Announced at Ordibehesht 1)

## Assignment Set 9

* Do this exercise step by step:

    - Generate some nonlinear data with m=300, based on a simple quadratic equation (2nd-degree)    
    - Fit a Polynomial Regression model to the data    
    - Apply a 200-degree polynomial model to the preceding training data, and compare(plot them) the result with a purely linear model and a quadratic model (2nd-degree polynomial)    
    - Plot the learning curves of the model’s performance on the training set and the validation set as a function of the training set size(or the training iteration)
    
-> Deadline: Saturday, Ordibehesht 27, 23:59 (Announced at Ordibehesht 20)

## Assignment Set 10

* Chapter 18 of [Understanding Machine Learning: From Theory to Algorithms](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning)

    - Exercises: 1 and 2
    
* Build a decision tree model to predict survival on the Titanic [dataset](https://github.com/codebasics/py/blob/master/ML/14_naive_bayes/titanic.csv), based on certain parameters (i.e., p-class, sex, age, and fare), then calculate the score of the model.
     
-> Deadline: Saturday, Khordad 3, 23:59 (Announced at Ordibehesht 20)

## Assignment Set 11

* Perform classification on the [MNIST](http://yann.lecun.com/exdb/mnist/), [Cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html), and [Cifar-100](https://www.cs.toronto.edu/~kriz/cifar.html) datasets, based on the following models and compare them:
  
   - Non-Ensemble Models (e.g., Decision Tree)
   - Ensemble Voting Classifiers (Both Soft and Hard)   
   - Bagging Classifier, Random Forests, and Extra Trees
   - AdaBoost Classifier
   - XGBoost Classifier
   
* Perform regression on the [California Housing Values](https://github.com/ageron/handson-ml/tree/master/datasets/housing) dataset, based on the following models and compare them:

   - Non-Ensemble Models (e.g., Decision Tree Regressor)
   - Random Forest Regressor 
   - AdaBoost Regressor
   - Gradient Boosting Regressor
   - XGBoost Regressor
   
* Write at least a paragraph about XGBoost and its advantages. (Optional: Advantage ~ 10 points)

**Please Note**: Datasets must be downloaded and injected manually (i.e., not loading them by libraries). Furthermore, small research should be done regarding the [XGBoost](https://github.com/dmlc/xgboost); For instance, take a look at the following [blog](https://towardsdatascience.com/a-beginners-guide-to-xgboost-87f5d4c30ed7) and [tutorial](https://www.kaggle.com/dansbecker/xgboost). In addition to them, try to develop very good classifiers and regressors based on each model, then compare their performance.

-> Deadline: Friday, Khordad 16, 23:59 (Announced at Khordad 4) 
   
 ## Assignment Set 12

* Chapter 11 of [Understanding Machine Learning: From Theory to Algorithms](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning)

   - Exercises: 1 and 2 

-> Deadline: Friday, Khordad 23, 23:59 (Announced at Khordad 12) 

## Assignment Set 13

* The [car evaluation](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation) [dataset](https://github.com/hhaji/Applied-Machine-Learning/blob/master/Recitation-Assignments/Assignments_Data/Assignment_Set_13_Data.csv) includes 1,728 records with six attributes (i.e., buying, maint, doors, persons, lug_boot, and safety) and four class values.

   - Depending on the class feature, cluster the data using the K-Means algorithm, and then test the results using the DBSCAN and Hierarchical methods. (Hint: Use the One-Hot method to digitize the required features.)
   
**Please Note**: You can take a look at part three of the session thirteen's Notebook.

-> Deadline: Friday, Khordad 30, 23:59 (Announced at Khordad 18) 

## Assignment Set 14

* PCA Implementation:

   - Use the Mushroom classification [dataset](https://www.kaggle.com/uciml/mushroom-classification).
   - Import all the needed modules, which include PCA, train_test_split, and labeling and scaling tools.
   - Encode the data with the LabelEncoder.
   - Use PCA to get the list of features and plot which features have the most explanatory power, or have the most variance.
   - Let's convert the features into the 17 top features, then plot a scatter plot of the data point classification based on them.
   - Do The previous step for the top 2 features and see how the classification changes.
   
* Singular Value Decomposition:

   - Write a function to load in an image and turn it into a Numpy array.
   - Select  the red, green, and blue color channels from the image.
   - Compress  the color channels.
   - Call  Numpy's SVD function on the color channel we want.
   - Create  an array of zeroes that you'll fill in after the matrix multiplication is completed.
   - Specify  the singular value limit you want to use when doing the calculations.
   - Use an image to test your SVD compression on.

-> Deadline: Friday, Tir 6, 23:59 (Advantage ~ 5 Points) - Friday, Tir 20, 23:59 (Announced at Tir 2)

## Assignment Set 15

* Perform classification on the following datasets based on support vector machine models:
  
   - [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist)   
   - [Cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html) and [Cifar-100](https://www.cs.toronto.edu/~kriz/cifar.html)
   - At least one other dataset (up to your choice, but should be different from those employed in previous assignments)  
   
* Perform regression on the following datasets based on support vector machine models:

   - [California Housing Values](https://github.com/ageron/handson-ml/tree/master/datasets/housing)
   - At least one other dataset (up to your choice, but should be different from those employed in previous assignments)

**Please Note**: Datasets must be downloaded and injected manually (i.e., not loading them by libraries). Moreover, you can find many datasets, for instance, on Kaggle. Besides, Try to develop very good classifiers and regressors based on each model. Furthermore, it would be much better to train (and experiment with) at least two models for each dataset. Careless model architectures and hyperparameter selections, which result in poor performance, will not be appreciated and may be scored very low! 

-> Deadline: Friday, Tir 6, 23:59 (Advantage ~ 5 Points) - Friday, Tir 20, 23:59 (Announced at Khordad 31!)

## Assignment Set 16

* Train neural network models (at least two different networks for each dataset, i.e., no. layers, no. neurons, activation, regularization, ...) in either Tensorflow or Pytorch to perform classification on the following datasets, then compare them with models in previous assignments:
  
   - [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist)   
   - [Cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html) and [Cifar-100](https://www.cs.toronto.edu/~kriz/cifar.html)
   - At least one other dataset (up to your choice, but should be different from those employed in previous assignments)  
   
* Train neural network models (at least two different networks for each dataset, i.e., no. layers, no. neurons, activations, regularization ...) in either Tensorflow or Pytorch to perform regression on the following datasets, then compare them with models in previous assignments:

   - [California Housing Values](https://github.com/ageron/handson-ml/tree/master/datasets/housing)
   - At least one other dataset (up to your choice, but should be different from those employed in previous assignments)
   
* Build and implement a simple neural network in either Python or C++ (i.e., not utilizing machine learning libraries). It should be capable of having several layers and neurons as well as other hyperparameters (e.g., activations, optimizer, loss function, and regularization). Object-oriented (class/objects) programming should also be employed. Then train and compare your models with the exact same architecture at Tensorflow (and Keras) and Pytorch for the following data:
   
   - A High-Degree Perturbed Polynomial
   - [California Housing Values](https://github.com/ageron/handson-ml/tree/master/datasets/housing)

**Please Note**: Datasets must be downloaded and injected manually (i.e., not loading them by libraries). Moreover, you can find many datasets, for instance, on Kaggle. Besides, Try to develop very good classifiers and regressors based on each model. Careless model architectures and hyperparameter selections, which result in poor performance, will not be appreciated and may be scored very low! 

-> Deadline: Friday, Tir 6, 23:59 (Advantage ~ 10 Points) - Friday, Tir 20, 23:59 (Announced at Khordad 31!)

# Final Project

* The final project will be considered as the outcome of the course, which is understanding and effective implementation of machine learning to provide practical solutions to realistic tasks. Two scenarios for the project can be imagined, applications and development of machine learning. Developing algorithms and methods is a valuable target, but may be challenging. On the other side, applications are highly recommended for this project. Students should decide on a topic for the project based on their interests as well as discussion with their mentor, who is one of the teaching assistants up to their choice. Mentors could provide advice and assistance during the topic selection and main progress. The following steps are expected: 

    - Selecting a Mentor and Deciding on a Topic
    - Writing a Brief Proposal (at least two paragraphs) of the Project
    - Proposal Approval by the Mentor
    - The Main Phase of the Project
    - Writing and Submitting the Final Report (at least three pages) as well as Codes and Data

-> Deadline: Firday, Tir 13, 23:59 (Proposal) - Friday, Mordad 3, 23:59 (Final Report and Codes) (Officially Announced at Khordad 31) 
 
**Please Note**: You can find many sample projects as well as datasets on [Kaggle](https://www.kaggle.com/). Moreover, take a look at final projects at Stanford's [CS229](http://cs229.stanford.edu/projects.html). The project will have a notable share in the final score of the course. Creativity and innovations are highly appreciated and will be rewarded accordingly. Projects will be examined by the Professor and teaching assistants. In addition to them, contacts with mentors/assistants are possible through email communications. However, in some cases, skype sessions may be arranged. 

**Proposal/Report Format and Submission**: The writing and structure of the two documents are important and will be evaluated. They should be in academic/publication format. Additionally, documents must be in PDF format, which are written either with LaTeX (Advantage ~ 5 Points) or MS Office, preferably in English. You can also use available templates. You should enter documents as well as codes and data into a repository named exactly "Applied_Machine_Learning_S20_Final_Project" (you can rename it once the course ended!). Please enter the title of your project as well as the link to its repository in the following link: [Registration](https://docs.google.com/document/d/1n4WDjIZMKNghwnWzMhJKfUPSfHzUeyb4eholMpyMILY/edit?usp=sharing)  

**Seminar Presentation**: Monday, Tir 6, 14:15 withing the [Skype Group](https://join.skype.com/kJ6WepEDrsnt) (It is recommended to prepare at least 5 pages for the presentation!) 

     Applied Machine Learning Seminar:
     
     1. Pegah Khazaei: Suicide Rates Overview 1985 to 2016
     2. Zahra Taheri: Spread Visualization and Prediction of the Novel Coronavirus Disease COVID-19 Using Machine Learning
     3. Fateme Rahimi: Recommendation Engine 
     4. Mohammad Azodi: Bank-Marketing
     5. Amir Mehrpanah: Apply Denoising Using Autoencoders
     6. Zahra Oruji: Twitter US Airline Sentiment analysis

# Submission Instruction 

* Please register through the link: [Registration](https://docs.google.com/document/d/1n4WDjIZMKNghwnWzMhJKfUPSfHzUeyb4eholMpyMILY/edit?usp=sharing)
* Create a repository inside your Github account with the exact name "Applied_Machine_Learning_S20_Assignments".
* Please review the [Projects](https://github.com/hhaji/Applied-Machine-Learning/tree/master/Projects) for further instructions.
* After completing all tasks of every assignment set, add related Jupyter notebooks (and/or other files) in a folder in the repository, for instance, assignments-1.ipynb inside Assingment_Set_1 folder, for the first set.
* Solutions of the exercises, as well as mathematical notations, could be written in [LaTeX](https://github.com/hhaji/Applied-Machine-Learning#latex) (Advantage ~ 10 Points), either in Jupyter notebook or PDF. MS Office or any other software (Advantage ~ 5 Points) could also be used, otherwise, images of your handwriting should be included, which is not recommended! Please acknowledge which one is used.

# Scores (Assignments and Projects)

* Scores announced at Mordad 6. Please visit the [Link](https://docs.google.com/spreadsheets/d/1ygd1pvTxv3YbedejVGhXTZJ349-rLdRuPKt32WkhXCY/edit?usp=sharing) for the scores.
* Each assignment set is scored from 100 points as well as extra rewards. Therefore, it can be more than 100.
* **Submission after the deadline will not be accepted!** Exceptionally, Assignments 1 to 6, could be submitted after their deadline up to Farvardin 26, but it is subjected to a penalty of 30 points.
* Failure to comply with the [Academic Honor Code](https://github.com/hhaji/Applied-Machine-Learning#academic-honor-code) will result in the ZERO score in each set and may have additional consequences!
* The score of the final project will be calculated from 100 points. It may also be more than 100 due to the added rewards! 
* The final score of assignments (1 to 16, excluding the final project) will be calculated based on the weighted average of them, from 100 points. Moreover, it may be more than 100 due to the added rewards! 
* Scores may be commented. Furthermore, students could also comment on their scores and request for re-evaluation in the form of email, which will be considered at the end of the course.  

<!--* Submission after the deadline is subjected to a penalty, which is 20 points for submission within a week after the deadline and 30 points for more than a week. --> 
